<!DOCTYPE html>
<html>
<head>
<link rel="stylesheet" type="text/css" href="style.css">
</head>
<body>
<img src = "images/I.png" align=right>
<h1>CS+Linguistics Undergraduate Major at UIUC</h1>
<table align="center">
	<tr>
		<td><a href="Home.html">Home</a></td>
		<td><a href="WhatIsCompLing.html">What is Computational Linguistics?</a></td>
		<td><a href="About.html">About the Degree</a></td>
		<td><a href="Transfer.html">Transferring Into the Program</a></td>
		<td><a href="Grad.html">Graduate Programs</a></td>
		<td><a href="Research.html">Research Opportunities</a></td>
		<td><a href="Intern.html">Internships and Jobs</a></td>
	</tr>
</table>

<img src="images/WhatIsCompLing.png">
<h2>What is Computational Linguistics?</h2>
<p><font size="5">"</font>Computational Linguistics, or Natural Language Processing (NLP), is not a new field. As early as 1946, attempts have been undertaken to use computers to process natural language. These attempts concentrated mainly on <b>Machine Translation</b> and, due to the political situation at the time, almost exclusively on the translation from Russian into English. Considerable resources were dedicated to this task, both in the U.S.A. and in Great Britain, during the fifties and sixties. Other countries, mainly in continental Europe, joined the enterprise, and the first systems ("SYSTRAN") became operational at the end of this period. However, the limited performance of these systems made it clear that the underlying theoretical difficulties of the task had been grossly underestimated, and in the following years and decades much effort was spent on basic research in formal linguistics. Today, a number of Machine Translation systems are available commercially although there still is no system that produces fully automatic high-quality translations (and probably there will not be for some time). Human intervention in the form of pre- and/or post-editing is still required in all cases.</p><br>
<p>Another application that has become commercially viable in the last years is the analysis and synthesis of spoken language, i.e., <b>speech understanding and speech generation</b>. Potential applications go from help for the handicapped (e.g., text-to-speech systems for the blind) to telephony based information systems (e.g., inquiry systems for train or plane connections, telebanking) and further on to office dictation systems (as offered by several vendors). Several text-to-speech systems are commercially available, and are in daily use in many places. The difficulties of speech understanding are much greater than those for speech generation yet some of the speech understanding systems are also entering the marketplace.</p><br>
<p>An application that will become at least as important as those already mentioned is the <b>creation, administration, and presentation of texts</b> by computer. Even reliable access to written texts is a major bottleneck in science and commerce. The amount of textual information is enormous (and growing incessantly), and the traditional, word-based, information retrieval methods are getting increasingly insufficient as either precision or recall is always low (i.e., you get either a large number of irrelevant documents together with the relevant ones, or else you fail to get a large number of the relevant ones in the collection). Linguistically based retrieval methods, taking into account the meaning of sentences as encoded in the syntactic structure of natural language, promise to be a way out of this quandary. However, the <b>creation</b> of texts is also becoming a problem. Manuals of complex technical systems (airplanes, computers etc.) are constantly out of date as the systems themselves are upgraded ever faster. Writing manuals by hand is thus getting ever more expensive and unreliable, and if manuals have to be maintained in different languages, manual production becomes increasingly unmanageable. If different versions of the manuals have to be written (for service users, for technicians, for auditors etc.), things get out of hand altogether. The automatic creation of manuals from a common knowledge base, in different languages and for different types of readers is a possible solution of this cluster of problems. The creation of natural language texts has always been a bit of "poor cousin" in the field of Computational Linguistics. The situation described is about to change this in a fundamental manner.</p><br>
<p>Another topic that might come to the forefront of research in Computational Linguistics is the <b>presentation of textual information</b>. Traditionally, text generation systems have created standard, i.e., linear, text. If the amount of text is large, and/or if different types of readers must be addressed, hypertext is a better medium of presentation. The automatic creation of hypertext from an underlying knowledge base calls for an extension of this traditional approach.<font size="5">"</font></p>
<p align="center">-<a href="http://www.aclweb.org/" target="_blank">Association for Computational Linguistics</a></p><br>
<p>For more information, visit the Association for Computational Linguistics' <a href="http://www.aclweb.org/aclwiki/index.php?title=Frequently_asked_questions_about_Computational_Linguistics" target="_blank">Frequently asked questions about Computational Linguistics</a> page.</p><br>

<p align="center"><font size="1">Last Updated: August 18, 2015</font></p>

</body>
</html>
